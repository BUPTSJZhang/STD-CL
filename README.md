# STD-CL
The official implementation of the paper 'Spatial-Temporal Decoupling Contrastive Learning for Skeleton-based Human Action Recognition'

### Abstract
Skeleton-based action recognition is a central task of human-computer interaction. However, most of the previous methods suffer from two issues: (i) semantic ambiguity arising from spatiotemporal information mixture; and (ii) overlooking the explicit exploitation of the latent data structure (i.e., the intra-class variation and inter-class relation), thereby leading to sub-optimal solutions. To mitigate this, we propose a spatial-temporal decoupling contrastive learning (STD-CL) framework to obtain discriminative and semantically distinct representations from the sequences. In particular, we decouple the global features into spatial-specific and temporal-specific features to reduce the spatiotemporal coupling of features. Furthermore, to explicitly exploit the latent data structure, we employ the attentive features to contrastive learning, which models the cross-sequence semantic relations by pulling together the features from the positive pairs and pushing away the negative pairs. Specifically, the proposed STD-CL can be incorporated into almost all previous methods. Without additional compute consumption in the testing phase, our STD-CL with four various backbones (HCN, 2S-AGCN, CTR-GCN, and Hyperformer) achieves significant improvement on NTU60, NTU120, and NW-UCLA benchmarks. 
